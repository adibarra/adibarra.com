---
title: Blog | Building TAMU Grades
display: Building TAMU Grades
date: 2025-01-01T06:00:00Z
lang: en
duration: 20min
subtitle: A writeup on how I built the TAMU Grades website.
upcoming: true
---

[[toc]]

## Wait, Again?

Yup, that's right, I re-wrote the original TAMU Grade Distribution website that I made in 2022 and posted about [here](/posts/tamugd-writeup). My goal with the original site was to learn about web development, and as a result, the code isn't great, and its UI/UX isn't much better.

<figure>
  <img src="/assets/posts/tamugd-writeup/final-product.png" alt="Screenshot of the original version" rounded-lg dark:border-1 border--c-tertiary />
  <figcaption class="caption">Screenshot of the original version</figcaption>
</figure>

Since then, the site has been getting a lot of traffic. So, I decided to re-design it from the ground up using the knowledge I gained over the last two years.

## Goals

The main goals for this re-write are:

> 1. **Improve UI/UX**: I want to make the new version much more visually appealing, ergonomic, and easier to use.
> 2. **Improve Performance**: I want to improve performance by using modern web technologies.
> 3. **Improve Code Quality**: I want to use a framework and build tools to make the codebase more maintainable.
> 4. **Add New Features**: I want to add new features like a natural language search.
> 5. **Make it Mobile Friendly**: I want the new version to work well on all devices.

## Tech Stack

The original version was built using plain JavaScript, HTML, and CSS. It lacked frameworks, build tools, or any modern workflow due to my inexperience at the time. The project was just a bunch of manually edited and minified files.

This approach led to a messy and unmaintainable codebase. So, I decided to use a proper tech stack for the new version.

### Frontend Development

One of the biggest changes was adopting a frontend framework. I chose <GithubLink repo="vuejs/vue" />, which I've been using for a while and really enjoy. I also decided to use <GithubLink repo="vitejs/vite" /> as the build tool since it's super fast and easy to use. Additionally, I decided to use <GithubLink repo="unocss/unocss" /> for its fantastic superset of atomic CSS classes to help style the site. I also utilized TypeScript throughout the application to catch errors early and improve code quality.

This modern setup makes the frontend **much** more maintainable and easier to work with. Using components and build tools has helped me clean up the codebase, making it more readable and extensible for future improvements.

Another decision I made was to not use a UI framework. Instead, I wanted to build the UI from scratch to learn more about CSS and design. Because of this, the new version has a more consistent look and feel compared to the original.

### Backend Development

This time around, I decided to use <GithubLink repo="fastify/fastify" /> as the backend framework. I also switched from MySQL to PostgreSQL, which is more powerful and widely used in production environments.

The backend is responsible for fetching data from the database and serving it to the frontend in both versions. However, the new backend also handles the scraping and parsing of the grade distribution data, which was previously done manually with a different script.

### Automation and Deployment

One of the most significant improvements I made was automating the build and deployment processes. Now, whenever I push changes to the repo, GitHub Actions are triggered. These actions build two Docker images: one for the backend and one for the frontend.

My deployment server automatically pulls these images and deploys the updated application. This setup allows me to easily deploy changes automatically without needing to worry about the build process.

Using Docker also helps with the portability of the application. It helps in ensuring consistency between development and production environments.

## Architecture

The old version of the site was divided into a static frontend and a backend, which served the frontend and handled database queries. The new version, however, keeps the two entirely separate. This is because the app is now built into two separate images. The frontend image includes an Nginx server that serves the static files generated by Vite, while the backend image includes the Fastify server that only serves the API and runs background tasks.

The project now uses a monorepo architecture with over 10 packages. This allows me to share code between the frontend and backend, such as types and constants while keeping them separate. It also makes it easier to manage dependencies and run scripts across the application.

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="Architecture diagram" rounded-lg />
  <figcaption class="caption">Architecture diagram</figcaption>
</figure>

This new architecture makes the project much more organized and easier to work with. It also allows me to scale the project more easily in the future by adding more packages for different parts of the application. For example, in the future, I could add a package for handling user authentication and import it anywhere in the application.

## Data Sourcing

This time around, I decided that I had two main goals for the data sourcing:

> 1. **Automate the Process**: I wanted to automate the scraping and parsing of the grade distribution data.
> 2. **Organize more Data**: I wanted to scrape and store more data than just the grade distributions.

### Finding the Data

The first step in the process was to find the data. For the grade distribution data, I once again opted to scrape PDFs from the Texas A&M Registrar's website. This script simply scrapes the main page and generates a list of URLs to PDFs that contain the grade distributions for each college, department, course, semester, and year.

However, the data that's available on the Registrar's website is limited. It only includes data from the past few years and doesn't include any course descriptions or information about professors. Due to this, I decided I also needed to scrape the course catalog pages and faculty directories to get more data.

Even with all this data, I found there were gaps in the data. For instance, some courses appeared in the grade distribution data but not in the course catalog. After some thought, I realized this was because the catalog only lists courses currently being offered. Due to this, despite having grade distribution data spanning many years, I lacked descriptions for those which were no longer offered.

In order to fill these gaps, I plan to scrape archived versions of the course catalog pages to get descriptions for these courses. This will allow me to provide more context to the grade distributions and make the site more useful.

### Scraping the Data

Next up, I needed to develop a method to scrape all of this data from the different data sources. In order to do this, I decided to simply write scrapers for each of the different data sources. These scrapers would then be run periodically and collect all of the raw data for further processing.

In this step, I also decided to implement a caching system to prevent unnecessary requests to the data sources. This would prevent the application from making requests for data that is already present or hasn't changed since the last request.

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="Caching scraper requests" rounded-lg />
  <figcaption class="caption">Caching scraper requests</figcaption>
</figure>

Preventing these requests helps minimize the load on the data sources to near zero and massively speeds up the scraping process. This is especially important when scraping the grade distribution data, as the PDFs can be quite large and take a long time to download.

### Parsing the Data

Once the data has been collected, it needs to be parsed and stored in a usable format. This is accomplished by a series of parsers that take the raw data and convert it into a format that can be stored in the database.

For the majority of the data sources, this process is quite straightforward. It simply uses <GithubLink repo="cheeriojs/cheerio" /> to parse the HTML which was previously scraped and extract the relevant information. However, for the grade distribution data, this process is a bit more complex.

The grade distribution data is stored in PDFs which are notoriously difficult to parse. In order to extract the data from these PDFs, I decided to use <GithubLink repo="mozilla/pdf.js" />. This library is the golden standard for rendering PDFs in browsers, but more importantly, it also provides an API for extracting text from PDFs.

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="The data parser in action" rounded-lg />
  <figcaption class="caption">The data parser in action</figcaption>
</figure>

Once the text has been extracted from the PDFs, I then run it though a secondary parser which converts the raw text into a more structured format. This is where the real heavy lifting happens. The parser needs to be able to handle a wide variety of different formats and structures in order to extract the grade distribution data.

This is because over the years, there have been many different formats used for the grade distribution data. While they mostly look the same, there are subtle differences in the way the data is presented. For example, some colleges list the grades using letters (A, B, C, etc.), while others include the +/- modifiers (A+, A, A-, etc.). Additionally, some of the PDFs are simply arranged differently, with different columns or headers because they include graduate courses.

In order to handle all of these different formats, the parser needs to be able to detect and adapt to these differences. This is accomplished by using a series of regular expressions and heuristics to identify the format of the data. Once the format has been identified, the system will load a corresponding parser that is able to extract the data from that format. This allows the system to be flexible and adapt to new formats as they are encountered.

The parsed data is stored in an intermediate JSON format. This format aims to be a 1:1 representation of all of the data as it appears in the PDFs. This approach simplifies debugging and verification before the data is entered into the database.

### Storing the Data

In order to store all of this data, I was going to need a much more complex database schema than the original. The original schema was very simple. It was essentially a single table with columns for the course, semester, year, and grade distribution data.

However, the new schema needed to be able to store much more data and maintain the relationships between them. I ended up with a schema that looks something like this:

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="The new database schema" rounded-lg />
  <figcaption class="caption">The new database schema</figcaption>
</figure>

This new schema allows me to store much more data, such as course descriptions, subjects, professors, and departments. This data can be used to provide more context to the grade distributions and allow for more advanced search functionality.

Additionally, it will allow me to build new features in the future, such as the ability to view grade distributions for specific professors or departments.

However, storing more data comes with its own set of challenges. The more data you store, the more complex the queries become. This can lead to slower performance and scalability issues. To mitigate this, I decided to heavily leverage indexes in order to massively speed up the queries. Additionally, I tested queries extensively to ensure they were as performant as possible.

Testing the queries helped identify bottlenecks and optimize them. I was able to reduce some queries from taking 500ms to less than 10ms by adding the right indexes and restructuring the queries.

## API Endpoints

The API is the bridge between the frontend and the database. It's responsible for fetching data from the database and serving it to the frontend in a usable format.

In the original version, this API was very simple. It consisted of two endpoints. The first was responsible for fetching all of the available departments. The second accepted a department ID and course number and returned the grade distribution data for that course.

The new version of the API has five endpoints.

### Search

The search endpoint allows users to search for courses by name, department, or course number. This endpoint accepts a query parameter and returns a list of courses that match the query.

The search functionality is powered by a full-text search index in the database. This index allows for fast and efficient searching of the course data. Additionally, the search endpoint uses a series of heuristics to rank the results based on relevance. This ensures that the most relevant results are returned first.

Tuning the search endpoint was a challenging task. I had to balance the different parts of the query to ensure that the results returned were always the most relevant. This involved tweaking the weights of the different parts of the query and testing the results to ensure they were accurate.

As mentioned earlier, there was also a lot of query optimization involved. The search endpoint is one of the most complex queries in the system. It involves unions of multiple tables and filtering the results based on a wide variety of criteria. This can lead to slow performance if not optimized correctly.

### Autocomplete

The autocomplete endpoint provides suggestions for course names, departments, and course numbers as the user types. This endpoint is powered by the same full-text search index as the search endpoint. It uses a series of heuristics to generate suggestions based on the user's input.

This endpoint is designed to be as fast as possible since it is meant to be used in real-time as the user types. To achieve this I had to find some creative ways to reduce the number of queries and optimize the ones that were necessary.

### Analyze

The analyze endpoint provides the grade distribution data for a specific course. This endpoint accepts a course ID and returns the grade distribution data for that course.

This endpoint is relatively simple compared to the others. It simply fetches the data from the database and returns it in a usable format. However, it is the core of the application. This means that it must be fast to ensure that the user experience is smooth.

### Shorten

The shorten endpoint generates a shortened URL for a set of user-defined filters. This allows users to share their searches with others by simply sharing a URL. When the URL is visited, the filters are applied, and the results are displayed.

This endpoint is also relatively simple. It checks the database to see if the filters have been used before and returns the existing URL if they have. If not, it generates a new URL and stores it in the database. This allows the system to reuse URLs and prevent duplicates.

The endpoint also keeps track of how many times each URL has been visited. This allows it to intelligently expire old URLs and prevent the database from growing too large over time.

### Expand

The expand endpoint expands a shortened URL and returns the filters used to generate it. This allows users to see the filters that were applied to a search by simply visiting the URL.

This endpoint is the reverse of the shorten endpoint. It simply fetches the filters from the database and returns them in a usable format. This allows the system to recreate the search and display the results to the user.

## UX/UI Design

The UX/UI design was one of the most important aspects of the new version. I wanted to make the site much more visually appealing, ergonomic, and easier to use.

### Design System

As mentioned earlier, I decided not to use a UI framework for the new version. The original site used a mixture of JQuery modules and CSS which created a very inconsistent look and feel. Instead, I wanted to build the UI from scratch to learn more about CSS and design.

The main goal of the new design was to make it clean, simple, and easy to use. I wanted to remove any unnecessary clutter and focus on the core functionality of the site.

### Prototyping

The first thing I did when creating the new design was to create a series of wireframes. These wireframes helped me visualize the layout of the site and plan out the different components.

The wireframes were helpful in planning out the different components and how they would interact with each other. They allowed me to experiment with different layouts and designs before committing to a final design. This helped me identify potential issues early on and make changes before they became problems.

#### Main Page

The main page of the site is where users will land when they first visit. I wanted to make this page as clean and simple as possible. So, I decided to take some inspiration from Google's search page and keep the design to a simple search bar.

<figure>
  <img src="/assets/posts/tamu-grades-writeup/wireframe-main.png" alt="Wireframe of the main page" rounded-lg />
  <figcaption class="caption">Wireframe of the main page</figcaption>
</figure>

At the top of the page, I also included a series of links to other parts of the site. This allows users to quickly navigate to different sections without making them intrusive.

#### Search Page

Hitting the search button on the main page will take the user to the search page where they can view the results of their search. This page uses the same search bar at the top of the page. However, it utilizes the rest of the available space to display the results. This allows users to quickly scan through the results and find the course they are looking for.

<figure>
  <img src="/assets/posts/tamu-grades-writeup/wireframe-search.png" alt="Wireframe of the search page" rounded-lg />
  <figcaption class="caption">Wireframe of the search page</figcaption>
</figure>

Another important feature of this page is the ability to tell at a glance which courses have certain attributes associated with them. For example, some courses may be crosslisted or be marked as having no data. These tags allows users to quickly identify these courses and filter them out if they are not interested. The results also include the number of credit hours each course is worth, which can be useful for students looking to fulfill specific requirements.

#### Analyze Page

Clicking on any result on the search page will take the user to the analyze page. This page displays all of the grade distribution data for the selected course. It also includes a series of filters that allow users to narrow down the results by semester, year, professor, and other criteria.

<figure>
  <img src="/assets/posts/tamu-grades-writeup/wireframe-analyze.png" alt="Wireframe of the analyze page" rounded-lg />
  <figcaption class="caption">Wireframe of the analyze page</figcaption>
</figure>

The main focus of this page is to make the graphs and tables as clear and easy to read as possible. However, there was also a lot of other information that I wanted to include.

For example, the page includes a section for the course description, prerequisites, and other information. This allows users to quickly get an overview of the course. Additionally, the page includes many filters that allow users to narrow down the results and focus on specific aspects of the data.

Some of the filters include the ability to filter by semester, year, professor, among other criteria.

### Components

Since part of the goal of the new version was to make the site more maintainable and easier to work with, I decided to break the UI down into a series of components. This allowed me to reuse components across the site and keep the codebase clean and organized.

I ended up building a little over 25 components. These range from simple components like buttons and inputs to more complex components like tables and graphs. Each component is designed to be as reusable as possible and can be easily customized to fit different parts of the site.

I'll briefly cover some of the more interesting or complex components.

#### SearchBox

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="The SearchBox component" rounded-lg />
  <figcaption class="caption">The SearchBox component</figcaption>
</figure>

The search box is one of the most crucial interfaces available on the app. It allows the user to type in a query and get a response back from the backend's API. At idle, the searchbox displays suggestions for search queries the user could make. This helps to demonstrate the many types of queries it can parse and return results for. However, once the user focuses the search box, it clears out the placeholder and waits for input. As the user begins typing the search box will query the Autocomplete endpoint on the API and return the single most likely query the user is typing in. This autocomplete result is this displayed in a lighter font as the user types which they can choose to accept in order to save time while searching.

The searchbox also has a secondary mode. It can be set to live-mode so that it does not wait for the user to hit the search button to query the API. This allows the site to instantly display query results as the user types their query. It also hides the search submission button since it is no longer necessary. This mode is currently used on the search page to help improve the user experience and make the site appear more responsive.

#### ChipSelect

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="The ChipSelect component" rounded-lg />
  <figcaption class="caption">The ChipSelect component</figcaption>
</figure>

I built the ChipSelect component to be generic and reusable across the site. It allows users to select multiple options from a list of choices, displaying the selected options as chips that can be easily removed with a click. The component also includes a search box, making it simple for users to filter the list and find specific options even when the list is extensive.

To power the search functionality, I integrated the <GithubLink repo="farzher/fuzzysort" /> library. This library enables fast and efficient fuzzy searching, allowing users to type any part of a choice and still get relevant results. This ensures a smoother and more intuitive experience, especially when dealing with long or complex lists of options.

The component uses two-way binding to keep the selected options in sync with the parent component. This means any changes in the selection immediately update the parent, making it easy to manage state across the app. Additionally, the selected options can be color-coded for better clarity, which is particularly useful for visually matching the selections to related data in graphs or other visualizations.

#### Chart

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="The Chart component" rounded-lg />
  <figcaption class="caption">The Chart component</figcaption>
  </figure>

I designed the Chart component to provide an interactive and visually appealing way to display the average GPA data over time. It was built by heavily leveraging the <GithubLink repo="amcharts/amcharts5" /> library. I took full advantage of its robust features while layering in customization so that it fit seamlessly with the app's design and functionality.

At its core, Chart uses reactive props to render the data passed to it. It accepts a list of datasets, each representing a professor's GPA data over several semesters, and a corresponding list of categories for the x-axis. The component ensures the chart stays up-to-date by watching for changes to these props and re-rendering the chart accordingly.

One of amChart's notable features is the availability of it's Default and Dark themes. By implementing some logic to dynamically switch between the themes as needed I was able to ensure the chart always matched the app's current theme. I was also able to leverage the responsiveness of the library to ensure the component looked great on any device. Regardless of the screen size, the layout dynamically adjusts to maintain clarity and usability.

To enhance user experience further, I added some smooth animations for both the chart itself and the data series. The animations help to make the component visually engaging as the data is being loaded. Additionally, each series is color-coded to represent different professors, making comparisons effortless at a glance.

#### CircleBar

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="The CircleBar component" rounded-lg />
  <figcaption class="caption">The CircleBar component</figcaption>
</figure>

This component was designed to represent percentages or parts of a whole. It consists of a circular bar that fills up based on the percentage value passed to it. The CircleBar component is highly customizable, allowing for easy adjustments to the text, size, color, and thickness of the bar. This flexibility ensures the component can be used in various contexts across the app.

The CircleBar component uses reactive props to update the bar's fill based on the percentage value passed to it. This ensures the component remains dynamic and responsive to changes in the data. The component also includes a text label that displays the percentage value by default, making it easy for users to interpret the data at a glance.

To enhance the visual appeal of the component, I added smooth animations to the bar's fill. The component's based on a circular SVG element which has it's stroke-dasharray and stroke-dashoffset properties animated to create the filling effect.

#### Datatable

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="The Datatable component" rounded-lg />
  <figcaption class="caption">The Datatable component</figcaption>
</figure>

The datatable component is another generic component. It accepts any arbitrary array of data and a function which translates an item in the array into an object which is rendered into a row in the table. This system allows the component to be used in a wide variety of contexts across the site.

The component also allows sorting the different columns by clicking on the column headers. This is done by calling the sort function with the column to sort by. The sort function then sorts the data based on the column and the current sort order of ascending or descending.

### The Final Product

After many iterations and refinements, I ended up with a design that I was happy with. The new version of the site is much more visually appealing, ergonomic, and easier to use than the original. It's also much more consistent and has a more modern look and feel compared to the original.

<figure>
  <img src="/assets/posts/tamu-grades-writeup/placeholder.png" alt="Screenshot of the analyze page" rounded-lg dark:border-1 border--c-tertiary />
  <figcaption class="caption">Screenshot of the analyze page</figcaption>
</figure>

The new version of the site is also much more responsive and works well on all devices. This was a big improvement over the original, which was not very mobile-friendly. The new version also loads much faster than the original, thanks to the modern tech stack and optimizations I made.

## Conclusion

During this project, I set out to improve my previously deployed site using the knowledge I've gained over the last two years. I wanted to make the new version much more visually appealing, ergonomic, and easier to use. I also wanted to improve performance by using modern web technologies and improve code quality by using a framework and build tools.

I'm happy to say that I believe I've achieved all of these goals. The new version is an improvement on the old one in every way, shape, and form. However, similarly to the original, I plan to continue implementing new features and improvements.

If you want to check out the site, you can find it [here](https://grades.adibarra.com). If you have any feedback or suggestions for the site, feel free to reach out to me on the project's feedback repo <GithubLink repo="adibarra/tamu-grades-feedback" /> or by email at <EmailLink to="adibarra00@gmail.com" />.
